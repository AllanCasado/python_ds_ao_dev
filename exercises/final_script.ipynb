{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f76b0e70",
   "metadata": {},
   "source": [
    "# Importação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95e78d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8689b1d5",
   "metadata": {},
   "source": [
    "# Definição das funções que serão usadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3363f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colors_and_composition(id):\n",
    "    #url em que a requisição será feita\n",
    "    url_model = f'https://www2.hm.com/en_us/productpage.{id}.html'\n",
    "\n",
    "    #fazendo a requisição\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36'}\n",
    "    page = requests.get(url_model, headers=headers)\n",
    "\n",
    "    #pegando o html da página\n",
    "    html = page.text\n",
    "\n",
    "    #criando um objeto do BeautifulSoup a partir do html\n",
    "    soup_product = BeautifulSoup(html)\n",
    "    \n",
    "    # ====================colors===========================\n",
    "    \n",
    "    #pegando todos os tipos de cores\n",
    "    product_colors = soup_product.find('ul', class_='inputlist clearfix')\n",
    "\n",
    "    #cores disponíveis daquele produto\n",
    "    colors = [product_item.find('a').get('data-color') for product_item in product_colors.find_all('li', class_='list-item')]\n",
    "    \n",
    "    # ====================composition===========================\n",
    "    attributes = list(filter(None, soup_product.find('div', class_='content pdp-text pdp-content').get_text().split('\\n')))\n",
    "\n",
    "    for i in range(len(attributes)):\n",
    "        if attributes[i] == 'Composition':\n",
    "                composition_shell = attributes[i+1]\n",
    "                composition_pocket = attributes[i+2]\n",
    "    \n",
    "    \n",
    "    return \"//\".join(colors), composition_shell, composition_pocket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70934889",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7deae1",
   "metadata": {},
   "source": [
    "## Job 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86618d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url em que a requisição será feita\n",
    "url = 'https://www2.hm.com/en_us/men/products/jeans.html'\n",
    "\n",
    "#parametros para fazer a requisição\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36'}\n",
    "\n",
    "#fazendo a requisição para pegar o html da vitrine\n",
    "page = requests.get(url, headers=headers)\n",
    "\n",
    "#pegando o html da página\n",
    "html = page.text\n",
    "\n",
    "#criando um objeto a partir do html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "#coletando quantos items existem ao total\n",
    "total_items = int(soup.find('h2', class_='load-more-heading').get('data-total'))\n",
    "\n",
    "#considerando que cada página mostra 36 produtos, vemos quantas paginas precisam\n",
    "page_number = int(round(total_items/36))\n",
    "\n",
    "#url para pegar todos os produtos\n",
    "url2 = url + \"?page-size=\" + str(page_number*36)\n",
    "\n",
    "#fazendo a requisição\n",
    "page = requests.get(url2, headers=headers)\n",
    "\n",
    "#pegando o html da página\n",
    "html = page.text\n",
    "\n",
    "#criando um objeto do BeautifulSoup a partir do html\n",
    "soup_pagination = BeautifulSoup(html)\n",
    "\n",
    "############################\n",
    "#####Nome, tipo e preço#####\n",
    "############################\n",
    "\n",
    "#buscando pela lista que contém todos produtos\n",
    "all_products = soup_pagination.find('ul', class_='products-listing small')\n",
    "\n",
    "#fazendo uma lista que tem o html de cada produto\n",
    "products_list = all_products.find_all('article', class_='hm-product-item')\n",
    "\n",
    "#listas para armazenar tipo e preço de cada produto\n",
    "products_id, products_type, products_price, products_name = [],[],[],[]\n",
    "\n",
    "#iterando em todos os produtos e pegando preço e tipo\n",
    "for product in products_list:\n",
    "    product_details = product.find('div', class_='item-details')\n",
    "    products_id.append(product.get('data-articlecode'))\n",
    "    products_type.append(product.get('data-category'))\n",
    "    products_price.append(product_details.find('span', class_='price regular').get_text())\n",
    "    products_name.append(product_details.find('a', class_='link').get_text())\n",
    "\n",
    "#criando um dataframe com os dados coletando até agora\n",
    "df = pd.DataFrame([products_id, products_name, products_type, products_price]).T\n",
    "df.columns = ['product_id', 'product_name', 'product_type', 'product_price']\n",
    "df['scrapy_datetime'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6fda12",
   "metadata": {},
   "source": [
    "## Job 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f02910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "#####Cores e composição#####\n",
    "############################\n",
    "\n",
    "#lista para armazenar as cores \n",
    "products_colors = []\n",
    "\n",
    "#lista para armazenar a composição\n",
    "products_composition_shell = []\n",
    "products_composition_pocket = []\n",
    "\n",
    "#para cada produto pegar as cores e composição e adicionar na lista\n",
    "for id in df['product_id']:\n",
    "    colors, composition_shell, composition_pocket = get_colors_and_composition(id)\n",
    "    products_colors.append(colors)\n",
    "    products_composition_shell.append(composition_shell)\n",
    "    products_composition_pocket.append(composition_pocket)    \n",
    "\n",
    "#adiciona as colunas de cores e composição do produto no dataframe\n",
    "df[\"product_colors\"] = products_colors\n",
    "df[\"product_composition_shell\"] = products_composition_shell\n",
    "df[\"product_composition_pocket\"] = products_composition_pocket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aafe6b",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89ec0caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reordenando as colunas\n",
    "df = df[[\"product_id\", \"product_name\", \"product_type\", \"product_colors\", \"product_price\", \"product_composition_shell\", \"product_composition_pocket\", \"scrapy_datetime\"]]\n",
    "\n",
    "#se a string não começar com \"Poc\" significa que esse valor não estava presente no site\n",
    "df[\"product_composition_pocket\"] = df[\"product_composition_pocket\"].apply(lambda x: x if x[:3] == \"Poc\" else np.nan)\n",
    "\n",
    "#limpando as colunas de composição do produto\n",
    "df[\"product_composition_shell\"] = df['product_composition_shell'].str.replace('Shell: ', '')\n",
    "df[\"product_composition_pocket\"] = df['product_composition_pocket'].str.replace('Pocket lining: ', '')\n",
    "df[\"product_composition_pocket\"] = df['product_composition_pocket'].str.replace('Pocket: ', '')\n",
    "\n",
    "#######uma linha por produto-cor########\n",
    "\n",
    "#dataframe final\n",
    "df_raw = pd.DataFrame()\n",
    "\n",
    "#para cada produto do df, extrai as cores e cria uma linha pra cada cor\n",
    "for i in range(len(df)):\n",
    "    #pega a linha\n",
    "    df_row = pd.DataFrame(df.loc[i]).T\n",
    "    #pega as cores daquele produto\n",
    "    unique_colors = df_row[\"product_colors\"].values[0].split(\"//\")\n",
    "    \n",
    "    #pra cada cor, cria uma nova linha\n",
    "    for i in range(len(unique_colors)):\n",
    "        df_row[\"product_colors\"] = unique_colors[i]\n",
    "        df_raw = pd.concat([df_raw, df_row])\n",
    "\n",
    "##########limpeza geral############\n",
    "\n",
    "#copiando o dataframe raw\n",
    "df_raw = df_raw.reset_index(drop=True)\n",
    "df = df_raw.copy()\n",
    "\n",
    "#######product_name##########\n",
    "df[\"product_name\"] = df[\"product_name\"].apply(lambda x: x.replace(\" \", \"_\").lower())\n",
    "\n",
    "######product_colors#########\n",
    "df[\"product_colors\"] = df[\"product_colors\"].apply(lambda x: x.replace(\" \", \"_\").lower())\n",
    "\n",
    "######product_price##########\n",
    "df[\"product_price\"] = df[\"product_price\"].apply(lambda x: x.replace(\"$\", \"\").strip())\n",
    "df[\"product_price\"] = df[\"product_price\"].astype(float)\n",
    "\n",
    "#####product_composition_shell#####\n",
    "\n",
    "# dataframe auxiliar\n",
    "df_aux = df.product_composition_shell.str.split(\",\", expand=True)\n",
    "\n",
    "# criar um dataframe de referência\n",
    "df_ref = pd.DataFrame(index=np.arange(len(df)), columns=[\"cotton\", \"spandex\", \n",
    "                                                         \"elastomultiester\", \"polyester\", \"lyocell\", \"rayon\"])\n",
    "\n",
    "#cotton\n",
    "df_cotton = df_aux[0].apply(lambda x: x if \"Cotton\" in x else np.nan)\n",
    "df_cotton = df_cotton.reset_index(drop=True)\n",
    "df_cotton.name = \"cotton\"\n",
    "\n",
    "df_ref = pd.concat([df_ref, df_cotton], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep=\"last\")]\n",
    "\n",
    "#spandex\n",
    "df_spandex = pd.Series(dtype=str)\n",
    "\n",
    "df_aux = df_aux.fillna(\"string vazia\")\n",
    "\n",
    "for i in df_aux.index:\n",
    "    spandex_in_1 = \"Spandex\" in df_aux.loc[i][1]\n",
    "    spandex_in_2 = \"Spandex\" in df_aux.loc[i][2]\n",
    "    if spandex_in_1:\n",
    "        df_spandex.loc[i] = df_aux.loc[i][1]\n",
    "    elif spandex_in_2:\n",
    "        df_spandex.loc[i] = df_aux.loc[i][2]\n",
    "    else:\n",
    "        df_spandex.loc[i] = np.nan\n",
    "        \n",
    "df_spandex.name = \"spandex\"\n",
    "\n",
    "df_ref = pd.concat([df_ref, df_spandex], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep=\"last\")]\n",
    "\n",
    "#elastomultiester\n",
    "df_elastomultiester = pd.Series(dtype=str)\n",
    "\n",
    "for i in df_aux.index:\n",
    "    elastomultiester_in_1 = \"Elastomultiester\" in df_aux.loc[i][1]\n",
    "    if elastomultiester_in_1:\n",
    "        df_elastomultiester.loc[i] = df_aux.loc[i][1]\n",
    "    else:\n",
    "        df_elastomultiester.loc[i] = np.nan\n",
    "\n",
    "df_elastomultiester.name = \"elastomultiester\"\n",
    "\n",
    "df_ref = pd.concat([df_ref, df_elastomultiester], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep=\"last\")]\n",
    "\n",
    "#polyester\n",
    "df_polyester = pd.Series(dtype=str)\n",
    "\n",
    "for i in df_aux.index:\n",
    "    polyester_in_1 = \"Polyester\" in df_aux.loc[i][1]\n",
    "    if polyester_in_1:\n",
    "        df_polyester.loc[i] = df_aux.loc[i][1]\n",
    "    else:\n",
    "        df_polyester.loc[i] = np.nan\n",
    "        \n",
    "df_polyester.name = \"polyester\"\n",
    "\n",
    "df_ref = pd.concat([df_ref, df_polyester], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep=\"last\")]\n",
    "\n",
    "#lyocell\n",
    "df_lyocell = pd.Series(dtype=str)\n",
    "\n",
    "for i in df_aux.index:\n",
    "    lyocell_in_0 = \"Lyocell\" in df_aux.loc[i][0]\n",
    "    lyocell_in_1 = \"Lyocell\" in df_aux.loc[i][1]\n",
    "    if lyocell_in_0:\n",
    "        df_lyocell.loc[i] = df_aux.loc[i][0]\n",
    "    elif lyocell_in_1:\n",
    "        df_lyocell.loc[i] = df_aux.loc[i][1]\n",
    "    else:\n",
    "        df_lyocell.loc[i] = np.nan\n",
    "        \n",
    "df_lyocell.name = \"lyocell\"\n",
    "\n",
    "df_ref = pd.concat([df_ref, df_lyocell], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep=\"last\")]\n",
    "\n",
    "#rayon\n",
    "df_rayon = pd.Series(dtype=str)\n",
    "\n",
    "for i in df_aux.index:\n",
    "    rayon_in_0 = \"Rayon\" in df_aux.loc[i][0]\n",
    "    rayon_in_2 = \"Rayon\" in df_aux.loc[i][2]\n",
    "    if rayon_in_0:\n",
    "        df_rayon.loc[i] = df_aux.loc[i][0]\n",
    "    elif rayon_in_2:\n",
    "        df_rayon.loc[i] = df_aux.loc[i][2]\n",
    "    else:\n",
    "        df_rayon.loc[i] = np.nan\n",
    "        \n",
    "df_rayon.name = \"rayon\"\n",
    "\n",
    "df_ref = pd.concat([df_ref, df_rayon], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep=\"last\")]\n",
    "\n",
    "#joining df_ref and df\n",
    "df = pd.concat([df, df_ref], axis=1)\n",
    "\n",
    "#drop product_composition column\n",
    "df = df.drop(\"product_composition_shell\", axis=1)\n",
    "\n",
    "#get only the number composition\n",
    "columns_composition = df_ref.columns\n",
    "for column in columns_composition:\n",
    "    df[column] = df[column].apply(lambda x: int(re.search('\\d+', x).group(0))/100 if pd.notnull(x) else x)    \n",
    "\n",
    "########product_composition_pocket########\n",
    "\n",
    "#drop product_composition_pocker because what really matter is the shell\n",
    "df = df.drop(\"product_composition_pocket\", axis=1)\n",
    "\n",
    "\n",
    "########scrapy_datetime#########\n",
    "\n",
    "#reordering the columns\n",
    "column_order = ['product_id', 'product_name', 'product_type', 'product_colors',\n",
    "       'product_price', 'cotton', 'spandex',\n",
    "       'elastomultiester', 'polyester', 'lyocell', 'rayon', 'scrapy_datetime']\n",
    "\n",
    "df = df[column_order]\n",
    "\n",
    "#convert to datetime type\n",
    "df[\"scrapy_datetime\"] = pd.to_datetime(df[\"scrapy_datetime\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "########Final Dataframe#######\n",
    "\n",
    "#dropping duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "#reseting index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "#fillna with 0, meaning that it doesn't compose the product\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6377aea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_type</th>\n",
       "      <th>product_colors</th>\n",
       "      <th>product_price</th>\n",
       "      <th>cotton</th>\n",
       "      <th>spandex</th>\n",
       "      <th>elastomultiester</th>\n",
       "      <th>polyester</th>\n",
       "      <th>lyocell</th>\n",
       "      <th>rayon</th>\n",
       "      <th>scrapy_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1024256001</td>\n",
       "      <td>slim_jeans</td>\n",
       "      <td>men_jeans_slim</td>\n",
       "      <td>black</td>\n",
       "      <td>24.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-01-07 19:32:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1024256001</td>\n",
       "      <td>slim_jeans</td>\n",
       "      <td>men_jeans_slim</td>\n",
       "      <td>light_denim_blue</td>\n",
       "      <td>24.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-01-07 19:32:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1024256001</td>\n",
       "      <td>slim_jeans</td>\n",
       "      <td>men_jeans_slim</td>\n",
       "      <td>denim_blue</td>\n",
       "      <td>24.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-01-07 19:32:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024256001</td>\n",
       "      <td>slim_jeans</td>\n",
       "      <td>men_jeans_slim</td>\n",
       "      <td>dark_blue</td>\n",
       "      <td>24.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-01-07 19:32:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1024256001</td>\n",
       "      <td>slim_jeans</td>\n",
       "      <td>men_jeans_slim</td>\n",
       "      <td>dark_denim_blue</td>\n",
       "      <td>24.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-01-07 19:32:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1024256001</td>\n",
       "      <td>slim_jeans</td>\n",
       "      <td>men_jeans_slim</td>\n",
       "      <td>dark_gray</td>\n",
       "      <td>24.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-01-07 19:32:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1024256001</td>\n",
       "      <td>slim_jeans</td>\n",
       "      <td>men_jeans_slim</td>\n",
       "      <td>white</td>\n",
       "      <td>24.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-01-07 19:32:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1096385002</td>\n",
       "      <td>loose_jeans</td>\n",
       "      <td>men_jeans_loose</td>\n",
       "      <td>black</td>\n",
       "      <td>29.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-01-07 19:32:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1096385002</td>\n",
       "      <td>loose_jeans</td>\n",
       "      <td>men_jeans_loose</td>\n",
       "      <td>dark_denim_blue</td>\n",
       "      <td>29.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-01-07 19:32:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1114023001</td>\n",
       "      <td>loose_jeans</td>\n",
       "      <td>men_jeans_loose</td>\n",
       "      <td>denim_blue</td>\n",
       "      <td>44.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-01-07 19:32:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id product_name     product_type    product_colors  product_price  \\\n",
       "0  1024256001   slim_jeans   men_jeans_slim             black          24.99   \n",
       "1  1024256001   slim_jeans   men_jeans_slim  light_denim_blue          24.99   \n",
       "2  1024256001   slim_jeans   men_jeans_slim        denim_blue          24.99   \n",
       "3  1024256001   slim_jeans   men_jeans_slim         dark_blue          24.99   \n",
       "4  1024256001   slim_jeans   men_jeans_slim   dark_denim_blue          24.99   \n",
       "5  1024256001   slim_jeans   men_jeans_slim         dark_gray          24.99   \n",
       "6  1024256001   slim_jeans   men_jeans_slim             white          24.99   \n",
       "7  1096385002  loose_jeans  men_jeans_loose             black          29.99   \n",
       "8  1096385002  loose_jeans  men_jeans_loose   dark_denim_blue          29.99   \n",
       "9  1114023001  loose_jeans  men_jeans_loose        denim_blue          44.99   \n",
       "\n",
       "   cotton  spandex  elastomultiester  polyester  lyocell  rayon  \\\n",
       "0    0.99     0.01               0.0        0.0      0.0    0.0   \n",
       "1    0.99     0.01               0.0        0.0      0.0    0.0   \n",
       "2    0.99     0.01               0.0        0.0      0.0    0.0   \n",
       "3    0.99     0.01               0.0        0.0      0.0    0.0   \n",
       "4    0.99     0.01               0.0        0.0      0.0    0.0   \n",
       "5    0.99     0.01               0.0        0.0      0.0    0.0   \n",
       "6    0.99     0.01               0.0        0.0      0.0    0.0   \n",
       "7    1.00     0.00               0.0        0.0      0.0    0.0   \n",
       "8    1.00     0.00               0.0        0.0      0.0    0.0   \n",
       "9    1.00     0.00               0.0        0.0      0.0    0.0   \n",
       "\n",
       "      scrapy_datetime  \n",
       "0 2023-01-07 19:32:27  \n",
       "1 2023-01-07 19:32:27  \n",
       "2 2023-01-07 19:32:27  \n",
       "3 2023-01-07 19:32:27  \n",
       "4 2023-01-07 19:32:27  \n",
       "5 2023-01-07 19:32:27  \n",
       "6 2023-01-07 19:32:27  \n",
       "7 2023-01-07 19:32:27  \n",
       "8 2023-01-07 19:32:27  \n",
       "9 2023-01-07 19:32:27  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
